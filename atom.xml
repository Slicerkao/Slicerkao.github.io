<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tr{Ceng Lou}]]></title>
  <link href="http://slicerkao.github.io/atom.xml" rel="self"/>
  <link href="http://slicerkao.github.io/"/>
  <updated>2018-07-20T00:13:25+08:00</updated>
  <id>http://slicerkao.github.io/</id>
  <author>
    <name><![CDATA[Ping Sheng Kao]]></name>
    <email><![CDATA[samk840125@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Study Note: Understanding Generative Adversarial Net (1)]]></title>
    <link href="http://slicerkao.github.io/blog/2018/07/11/study3/"/>
    <updated>2018-07-11T21:25:48+08:00</updated>
    <id>http://slicerkao.github.io/blog/2018/07/11/study3</id>
    <content type="html"><![CDATA[<p>Recently a bunch of Generative Adversarial Net (GAN) related research has boomed in the unsupervised learning community, and it seems interesting to fully understand the mechanism of this novel learning framework. Just a few days ago (July 5th, 2018), Alexia Jolicoeur-Martineau et al proposed a <a href="https://arxiv.org/abs/1807.00734">Relativistic GAN</a> that aimed to provide improvement via changes of the discriminator term in the original GAN objective function. It pointed out that the real data are usually ignored during the learning process in most GAN paradigm, and thus it proposed a relativistic quantity to measure how ‘real’ the real samples are compared to the fake sample.</p>

<p><img src="http://slicerkao.github.io/images/de.png" alt="alt text" /></p>

<!--more-->

<p>It seems to to me that the original goal of GAN is to train the followings given the sampled real data sets $x_i \mathop{\sim}^{i.i.d} P$:</p>

<ul>
  <li>
    <p>A generator $G_{\theta}(z)$ that has small distributional divergence with respect to the true distribution. This is the main goal of the generative learning paradigm.</p>
  </li>
  <li>
    <p>A discriminator $D_{\omega}$ equipped with strong detection ability. This is rather a side product for GAN, but the training procedure relies on the detection result (e.g. the backpropagation for weight update.)</p>
  </li>
</ul>

<h3 id="generator-perspective-minimization-of-the-divergence">Generator perspective: minimization of the divergence</h3>

<p>For the first part, most GAN objective functions are some $f$ divergence with the following forms:</p>

<p>\begin{eqnarray}
&amp;&amp; D_f(P||Q) = \int_{\chi} q(x)f \Big( \frac{p(x)}{q(x)}\Big) dx
\end{eqnarray}</p>

<p>As pointed out in the <a href="https://arxiv.org/abs/1606.00709">$f$ GAN literature</a>, the $f$ divergence is approximated via a variational lower bound known as Frenchel conjugate $f^\ast$ (for all lower-semicontious function $f$). This conjugate is convex with the defintion:</p>

<p>\begin{eqnarray}
&amp;&amp; f^\ast (t) = \mathop{\sup}_{u \in {\rm dom}_f} [ut - f(u)]
\end{eqnarray}</p>

<p>Likewise, $f$ can be expressed in terms of $f^\ast$ since the pair $(f, f^\ast)$ are dual to each other. Plugging into the expression of the $f$ divergence, we have:</p>

<p>\begin{eqnarray}
&amp;&amp; D_f(P||Q) = \int_{\chi} q(x) \mathop{\sup}_{t \in {\rm
dom} _{f^\ast}} \Big( t\frac{p(x)}{q(x)} - f^\ast(t) \Big) dx \newline 
&amp;&amp; \geq \sup _{T(x) \in \mathcal{T}} \Big( \int _{\chi} p(x) T(x) dx - \int _{\chi} q(x) f^\ast (T(x)) \Big) \newline
&amp;&amp; = \sup _{T(x) \in \mathcal{T}} (E _{x \sim P}[T(x)] - E _{x \sim Q}[f^ \ast (T(x))])
\end{eqnarray}</p>

<p>To achieve the tightest lower bound, $T(x) = \frac{df}{dx} \big(\frac{p(x)}{q(x)}\big)$. For instance, consider a $f$ divergence with $f(u) = u \log u - (u+1) \log (u+1)$, first compute the Frenchel dual as :</p>

<p>\begin{eqnarray}
&amp;&amp; f^\ast (t) = \mathop{\sup} _{u &gt; 0} [ut - u \log u + (u+1) \log(u+1)] \newline
&amp;&amp; = - (t + \log (10^{-t} - 1)) \; , \; t &lt; 0 
\end{eqnarray}</p>

<p>So the variational lower bound for the $f$ divergence becomes :</p>

<p>\begin{eqnarray}
&amp;&amp; \sup _{T(x) \in \mathcal{T}} (E _{x \sim P}[T(x)] + E _{x \sim Q}[\log (1 - exp(T(x)))])
\end{eqnarray}</p>

<p>Standard GAN adopts $T(x)$ with the form :</p>

<p>\begin{eqnarray}
&amp;&amp; T(x) = \log D_\omega(x) = 1/(1 + e^{-V_{\omega}(x)})
\end{eqnarray}</p>

<p>So the loss is the familiar form :</p>

<p>\begin{eqnarray}
&amp;&amp; L(\theta, \omega) = \mathop{\sup} _{D} [E _{x \sim P}[\log D _{\omega}(x)] + E _{x \sim G _{\theta}(P_z)}[\log (1 - D _{\omega}(x))]]
\end{eqnarray}</p>

<p>When $D(x)$ is optimal, it has $D(x) = \frac{p(x)}{p(x) + G_{\theta} (P_z)(x)}$, or with $Q_{\theta} = G_{\theta}(P_z)$ as a shorthand, $D(x) = \frac{p(x)}{p(x) + q_{\theta}(x)}$. Plugging it back to the variational bound, one can recover the J-S divergence in the literature. Thus with a perfect discriminator, the generator can be trained to minimize the divergence loss between generated distribution and the target distribution.</p>

<h3 id="discriminator-perspective-optimal-detector">Discriminator perspective: Optimal Detector</h3>

<p>The above arguments stand on a generator perspective, where the goal is to
minmize a divergence measure (with high fidelity). On the other hand, we’ve seen that the optimal discriminator to construct JS divergence is actually a maximum likelihood detector. ML is also an optimal detector for hypthothesis testing with uniform prior, where the performance metric is the Bayesian risk. Such a correspondence between divergence measure and the optimal Bayesian detector is not a coincidence: The form of the standard GAN variational lower bound takes a log-likelihood expression. i.e, when jointly maximize the log of true alarm and negative probability, one get a J-S divergence measure with a Bayesian optimal detector.</p>

<p>For more example, consider a variational objective with $0-1$ loss, i.e.,</p>

<p>\begin{eqnarray}
&amp;&amp; L(\theta, \omega) = \mathop{\sup} _{D : \chi \to 0, 1} [ E _{x \sim P}[\mathbb{1}[D _{\omega}(x)]] + 
E _{G _{\theta}(z) \sim Q}[1 - \mathbb{1}[D _{\omega}(G _{\theta}(x))]]]
\end{eqnarray}</p>

<p>This loss is exactly (up to a 1/2 prior probability) related to the Bayesian risk, and the maximization of it leads to a divergence measure called total variance $d_{\rm TV}(P,Q)$, defined as:</p>

<p>\begin{eqnarray}
&amp;&amp; d_{\rm TV}(P,Q) = \mathop{\sup}_{S \subset \chi} [P(S) - Q(S)] = L(\theta, \omega^\ast) - 1
\end{eqnarray}</p>

<p>So to construct an optimal detector in a sense of the Baysian risk, the discriminator should jointly maximize the true positive and negative probability. And its maximum is $1 + d _{\rm TV}(P,Q)$. Likewise, standard GAN jointly maximize the log likelihood of true positive and negative probabilty, which yields an optimal value expressed by the J-S divergence. For other GAN, one can also trace the decision region of the optimal discriminator, and may understand if such a GAN bias toward true positive or true negative probability.</p>

<h3 id="dose-gan-bias-toward-true-positive-or-true-negative-during-the-training-process-">Dose GAN bias toward true positive or true negative during the training process ?</h3>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Briefing : Derivation of the uniform convergence]]></title>
    <link href="http://slicerkao.github.io/blog/2018/06/21/study2/"/>
    <updated>2018-06-21T15:57:36+08:00</updated>
    <id>http://slicerkao.github.io/blog/2018/06/21/study2</id>
    <content type="html"><![CDATA[<p>The following notes are summarized from Prof I-Hsiang Wang’s lecture: <a href="http://homepage.ntu.edu.tw/~ihwang/Teaching/Sp18/MPML.html"> Mathematic  Principles  of  Machine  learning</a>, Lec 3 for</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Briefing : PAC learnibility]]></title>
    <link href="http://slicerkao.github.io/blog/2018/06/19/study-note-2/"/>
    <updated>2018-06-19T16:47:04+08:00</updated>
    <id>http://slicerkao.github.io/blog/2018/06/19/study-note-2</id>
    <content type="html"><![CDATA[<p>The following notes are summarized from Prof I-Hsiang Wang’s lecture: <a href="http://homepage.ntu.edu.tw/~ihwang/Teaching/Sp18/MPML.html"> Mathematic  Principles  of  Machine  learning</a>, covering lecture 1 and 2.</p>

<!--more-->

<h3 id="discriminative-learning-consistency-and-no-free-lunch">Discriminative learning, Consistency and No free lunch</h3>

<p>In the setting of discriminative learning, <em>excessive risk</em> $R_{exessive}$ is decomposed into estimation error (which is associated with sampling bias) and the approximation error (which is associated with the size of the functional class $\mathcal{F}$) as :</p>

<p>$R_{excessive}  = L(f, P)- L(f^* ,P) = (L(f, P) - \mathop{\inf}_{f_n \in \mathcal{F}} L(f_n, P)) \longrightarrow \; {\rm estimation \; error}$</p>

<p>$+ \; ( \mathop{\inf}_{f_n \in \mathcal{f}} L(f_n, p) - L(f^* , p))
\longrightarrow \; {\rm approximation \; error}$</p>

<p>where $f^{\ast}$  denotes the Baysian optimal rule. The term <em>consistency</em> for a sequence of learning algorithms $f_n $ and a distribution $\mathcal{P}$ is defined as:
\begin{eqnarray}
&amp;&amp; L(f_n ; P) - L(f^* ; P) \mathop{\rightarrow}^{L_1}0 \; as \; n \rightarrow \infty
\end{eqnarray}</p>

<p>And with loss bounded from above, by dominate convergence theorem the
consistency criteria is equivalent to convergence in probability:
\begin{eqnarray}
\forall \, \epsilon &gt; 0, \; \mathop{\lim}_{n \leftarrow \infty} P^{\otimes n}[|L(f_n; P)- L(f^*; P)| &lt; \epsilon ] = 1 
\end{eqnarray}</p>

<p>Impossibility result holds for general learning paradigms as well as
discriminative paradigm. No free lunch theorem states the existence of bad
distribution such that small excessive risk can’t be achieved with finite
samples. Therefore discriminative approach confine the functional group to circumvent bad convergent behaviour. This derives the concept of PAC learnibility: There’re some functional class being learnbable, and some that are not.</p>

<p>Note that the lower bound for the imposibility results is established via a key observation: If a
distribution $\mathcal{P}$ is concentrated on a finite set of data $X$ with $P(Y|X)$ being deterministic , then the algorithm output can be highly biased. It’s due to the fact that the training data may not cover all of the element in $X$, which make the algorithm only conduct random guess for the unseen data. (i.e. $f(X_1,Y_1, X_2, Y_2 \dots X_n, Y_n) \perp Y_{\rm test} $)</p>

<h3 id="pac-learnable-realizability">PAC learnable, realizability</h3>

<p>In the discriminative paradigm we aim to minimize the estimation error $\Xi_{\mathcal{F}}(L,P) = L(f,P) -
\mathop{\inf}_{f_n \in \mathcal{F}}L(f_n, P)$, and we’re interested in the
number of samples required to achieve certain ($\epsilon, \delta $)
generalization guarantee. Define the sample complexity of a hypothesis class
$\mathcal{F}$ as</p>

<p>\begin{eqnarray}
&amp;&amp; n_{\mathcal{F}}(\epsilon, \delta) \mathop{=}^{\Delta} {\rm min}[n: \, \exists f_n \in \mathcal{F} \, {\rm s.t.} \, \forall P, \, P^{\otimes n}[\Xi_{\mathcal{F}}(f_n, P) \leq \epsilon] \geq 1-\delta]
\end{eqnarray}</p>

<p>So if there’s some learning algorithm $f_n \in \mathcal{F}$ that guarantee estimation error to be less than
$\epsilon$ with high confident level and finite sample for all distribution,
than such a functional class in PAC learnable.</p>

<p>ERM rule provide a sufficient condition of PAC learnability, via 
\begin{eqnarray}
&amp;&amp; \Xi_{\mathcal{F}}(f_{ERM},P) \leq 2 \mathop{\sup}_{f\in \mathcal{F}}|\Delta
(f,P)|
\end{eqnarray}</p>

<p>Where $\Delta (f, P)$ is the deviation between true risk and the empirical risk.</p>

<p><em>Realizability</em> indicates a existance of $f \in \mathcal{F}$ such that L(f,P) is
zero, which is equivalent to $\ell (f(X), Y) = 0$ with probability one. In this
case:</p>

<ul>
  <li>
    <p>ERM always achieve zero emprirical risk.</p>
  </li>
  <li>
    <p>$f^{*}$ is a deterministic fuction</p>
  </li>
</ul>

<p>Thus any <em>bad</em> function $f_{\rm bad} \in \mathcal{F}$ is less probable to be
picked out from ERM rule. This indeed provided a sample commplexity with smaller
scaling factor $\mathcal{O}(\epsilon^{-1})$, as compared with the agnostic case
$\mathcal{O}(\epsilon^{-2})$</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Study Note: Max of subgaussian]]></title>
    <link href="http://slicerkao.github.io/blog/2018/06/19/study-note/"/>
    <updated>2018-06-19T14:46:06+08:00</updated>
    <id>http://slicerkao.github.io/blog/2018/06/19/study-note</id>
    <content type="html"><![CDATA[<p>Given $n$ independently distributed sub-gaussian random variable $Z_i$, each has bounded MGF due to sub gaussian property:</p>

<p>\begin{eqnarray}
&amp;&amp; E[e^{Z_i}] \leq e^{\lambda^2 \sigma^2 /2 } \;\;\; \forall i = 1 \dots n
\end{eqnarray}</p>

<p>for some $\lambda$ being postive real number. Let $X = \mathop{\max}_{1\leq i \leq n } Z_i$, one has that:</p>

<p>\begin{eqnarray}
&amp;&amp; E[X] \leq \sigma \sqrt{2 \log n} 
\end{eqnarray}
<!--more--></p>

<p>To prove this, note that the aim is to upper bound the expected value $E[X]$; thus Jensen’s inequality comes in handy:</p>

<p>\begin{eqnarray}
&amp;&amp; e^{t E[X]} \leq E[e^{t X}] = E[\mathop{\max}_{1\leq i \leq n} e^{t Z_i}] \leq \sum _{i=1} ^{n} E[e^{t Z_i}] \leq n e^{t^2 \sigma^2 /2}
\end{eqnarray}</p>

<p>Thus 
\begin{eqnarray}
&amp;&amp; E[X] \leq \frac{\log n}{t} + t \sigma ^2 /2 \leq \sigma \sqrt{2 \log n} 
\end{eqnarray}</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Briefing: Quantum Adiabatic Search (2001)]]></title>
    <link href="http://slicerkao.github.io/blog/2018/04/29/study-note-quantum-adiabatic-search-2001/"/>
    <updated>2018-04-29T18:29:47+08:00</updated>
    <id>http://slicerkao.github.io/blog/2018/04/29/study-note-quantum-adiabatic-search-2001</id>
    <content type="html"><![CDATA[<p>In this post, a quantum adiabatic method applied to search problem is summarized and commented. All the following context is based on <a href="https://arxiv.org/abs/quant-ph/0107015">$\rm Quantum \, Search \, by \, Local \, Adiabatic \, Evolution$</a> from J$\acute{e}$r$\acute{e}$mie Roland and Nicolas J. Cerf.</p>

<!--more-->

<h3 id="adiabatic-theorem">Adiabatic Theorem</h3>

<p>Given a time dependent Hamiltonian $H(t)$, let $\vert E_k \, ; t \rangle$ be the eigenstate of $H(t)$ such that:</p>

<p>\begin{eqnarray}
&amp;&amp; H(t)|E_k \, ; t\rangle = E_k(t)|E_k \, ; t\rangle
\end{eqnarray}</p>

<p>where $E_k$ denotes the k-th eigenvalue of the Hamiltonian. Also, define the minimum eigengap $g_{min}$ as:</p>

<p>\begin{eqnarray}
&amp;&amp; g_{min} = \mathop{\min}_{0 \leq t \leq T}|E_1(t)-E_0(t)| 
\end{eqnarray}</p>

<p>Then one version of the adiabatic theorem states that if $g_{min}$ within the evolution time $T$ is not too small (compared to the variation of the Hamiltonian), then the initial state $\vert E_0 \, ; t\rangle$ evolves to $\psi(T)$ that’s close to $\vert E_0 \, ; T\rangle$. Intuitively, larger eigengap implies less quantum transition from base state to the first activated state, and thus the wave fuction “stay” at the base state throughout the evolution.</p>

<p>Formally, the variational quantity of $H$ is denoted by $\langle \frac{dH}{dt} \rangle_{1,0}$ as:</p>

<p>\begin{eqnarray}
&amp;&amp; \langle \frac{dH}{dt} \rangle_{1,0} = \langle E_1;t | \frac{dH}{dt}|E_0;t\rangle
\end{eqnarray}</p>

<p>Then provided that</p>

<p>\begin{eqnarray}
&amp;&amp; \frac{\langle \frac{dH}{dt}\rangle_{1,0}}{g^2_{min}} \leq \epsilon
\end{eqnarray}</p>

<p>one could evolve the state $\vert E_0;0\rangle$ toward state $\psi(T)$ such that:</p>

<p>\begin{eqnarray}                                                               <br />
&amp;&amp; |\langle E_0;T|\psi(T)|^2 \geq 1- \epsilon^2
\end{eqnarray}</p>

<h3 id="a-construction-of-an-adiabatic-search-algorithm">A construction of an adiabatic search algorithm</h3>

<p>Adiabatic thereom can  be appllied to construct a quantum search algorithm.
Consider a problem to find $\vert m \rangle$ out of $N$ computational basis.  Let $\vert \psi_0 \rangle$ be a uniform superposition of computational basis:</p>

<p>\begin{eqnarray}
&amp;&amp; |\psi_0\rangle = \frac{1}{\sqrt{N}}\sum^N_{i=1}|i\rangle
\end{eqnarray}</p>

<p>Define two Hamiltonians $H_0$ and $H_m$ and their time dependent interpolation $H(t)$ as:</p>

<p>\begin{eqnarray}
&amp;&amp; H_0 = I - |\psi_0\rangle\langle\psi_0| \newline
&amp;&amp; H_m = I - |m\rangle\langle m| \newline
&amp;&amp; H(t) = (1-t/T)H_0 + t/T H_m
\end{eqnarray}</p>

<p>Note that $\vert\psi_0\rangle$ and $\vert m\rangle$ are the base states of $H_0$ and $H_m$. To have the adiabatic theorem hold, one need to impose the condition on the only adjustable parameter $T$. First, solve the eigen problem of $H(t)$:</p>

<p>\begin{eqnarray}
&amp;&amp; H(t)|E_k ; t\rangle = E_k |E_k; t\rangle \newline
&amp;&amp; (I-(1-t/T)|\psi_0\rangle\langle \psi_0|-t/T|m\rangle\langle m|)|E_k ; t\rangle = E_k |E_k; t\rangle \newline
\end{eqnarray}</p>

<p>let $a_k=\langle\psi_0\vert E_k;t\rangle$, $b_k=\langle m \vert E_k;t\rangle$, and note that $\langle m \vert \psi_0\rangle = \frac{1}{\sqrt{N}}$, one obtain the following relations by applying the inner product of $\vert m\rangle$ and $\vert\psi_0\rangle$ to the above equation:</p>

<p>\begin{eqnarray}
&amp;&amp; (t/T-E_k)a_k = t/T\frac{1}{\sqrt{N}}b_k \newline
&amp;&amp; (1-t/T-E_k)b_k = (1-t/T)\frac{1}{\sqrt{N}}a_k
\end{eqnarray}</p>

<p>Solving the eigenvalue, with $s = t/T$ one obtain the (degenerate) eigevalue of $H(t)$:</p>

<p>\begin{eqnarray}
&amp;&amp; E_0 = \frac{1}{2}(1-\sqrt{4(1-\frac{1}{N})s^2-4(1-\frac{1}{N})s+1}) \newline
&amp;&amp; E_1 = \frac{1}{2}(1+\sqrt{4(1-\frac{1}{N})s^2-4(1-\frac{1}{N})s+1})
\end{eqnarray}</p>

<p>Then the eigengap $g$ is
\begin{eqnarray}
&amp;&amp; g = \sqrt{1-4\frac{N-1}{N}s(1-s)}
\end{eqnarray}
with minimum reached at $s=1/2$ with $g_{min}=1/\sqrt{N}$.</p>

<p>Following up with the calculation of the variational quantity $\langle\frac{dH}{dt}\rangle_{1,0}$:</p>

<p>\begin{eqnarray}
&amp;&amp; \langle\frac{dH}{dt}\rangle_{1,0} = \langle E_1;t|\frac{1}{T}(H_m - H_0)|E_0;t\rangle \newline
&amp;&amp; = \langle E_1;t|\frac{1}{T}(|\psi_0\rangle\langle \psi_0| - |m\rangle \langle m|)|E_0;t\rangle \newline
\end{eqnarray}</p>

<p>It can be proven that the absolute value of this quantity is less than
$\frac{1}{T}$. Thus,
the adiabatic condition reads:</p>

<p>\begin{eqnarray}
&amp;&amp; T \geq N/\epsilon
\end{eqnarray}</p>

<p>which yields no benefit over classical algorithm.</p>

<h3 id="a-variant-of-the-interpolation-rate-st">A variant of the interpolation rate s(t)</h3>

<p>To achieve quantum speedup, notice that the adiabatic condition can be applied to a infinitesimal scale of time. That is, let $s(t)$ be an unknown function of $t$, and then impose the adiabatic condition:</p>

<p>\begin{eqnarray}
&amp;&amp;\frac{ds}{dt} \leq \epsilon \frac{g^2(t)}{|\langle\frac{dH}{ds}\rangle_{1,0}|}
\end{eqnarray}</p>

<p>Along with previous calculation of the eigengap $g$, one can choose the
following to have the local adiabatic condition hold :
\begin{eqnarray}
&amp;&amp; \frac{ds}{dt} = \epsilon g^2(t)
\end{eqnarray}</p>

<p>Solving $s(t)$ with boundary condition $s(0)=0, s(T)=1$, one obtain 
\begin{eqnarray}
&amp;&amp; T = \frac{\pi}{2\epsilon} \sqrt{N}
\end{eqnarray}
by taking $s = 1$ and $N \gg 1$. This achieve the Grover’s search performance as wanted.</p>

<p>To prove the optimality of the choice $s(t)$, the search problem can be solved if the evolved answers of different target are sufficiently discriminable. That is, let $\vert\psi_m ;t \rangle$ and $\vert\psi_{m’};t\rangle$ be the volved state after time $t$ for search target $m$ and $m’$ respectively, we require that:</p>

<p>\begin{eqnarray}
&amp;&amp; 1- |\langle \psi_{m}; T| \psi_{m’}; T\rangle|^2 \geq \delta \; 
\end{eqnarray}</p>

<p>From Schrodinger’s equation, we have the followings:</p>

<p>\begin{eqnarray}
&amp;&amp; i \frac{d}{dt}|\psi_m ; t\rangle = (I - (1-s)|\psi_0\rangle\langle\psi_0| - s|m\rangle\langle m|)|\psi_m;t\rangle \newline
&amp;&amp; i \frac{d}{dt}|\psi_m’ ; t\rangle = (I - (1-s)|\psi_0\rangle\langle\psi_0| - s|m’\rangle\langle m’|)|\psi_{m’};t\rangle 
\end{eqnarray}</p>
]]></content>
  </entry>
  
</feed>
