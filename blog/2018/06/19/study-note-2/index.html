
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="ja"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Briefing : PAC learnibility - Tr{Ceng Lou}</title>
  <meta name="author" content="Ping Sheng Kao">

  
  <meta name="description" content="The following notes are summarized from Prof I-Hsiang Wang’s lecture: Mathematic Principles of Machine learning, covering lecture 1 and 2. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://slicerkao.github.io/blog/2018/06/19/study-note-2/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Tr{Ceng Lou}" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$']],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea',
        'pre', 'code']
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX",
      availableFonts: ["STIX","TeX"] }
  });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  
</head>
<body >
  <div id="container">
    <header role="banner"><hgroup>
  <h1><a href="/">Tr{Ceng Lou}</a></h1>
  
    <h2>Study Notes</h2>
  
</hgroup></header>
    <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="site:slicerkao.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul></nav>
    <div id="main">
      <div id="content">
        <div>
<article class="hentry" role="article">
  <header>
    
      <h1 class="entry-title"><a href="">Briefing : PAC Learnibility</a></h1>
    
    
      <div class="post-meta">
        <p class="meta">
          <span class="timestamp">- <time datetime="2018-06-19T16:47:04+08:00" pubdate data-updated="true"></time> -</span>
          
        </p>
      </div>
    
  </header>


<div class="entry-content"><p>The following notes are summarized from Prof I-Hsiang Wang’s lecture: <a href="http://homepage.ntu.edu.tw/~ihwang/Teaching/Sp18/MPML.html"> Mathematic  Principles  of  Machine  learning</a>, covering lecture 1 and 2.</p>

<!--more-->

<h3 id="discriminative-learning-consistency-and-no-free-lunch">Discriminative learning, Consistency and No free lunch</h3>

<p>In the setting of discriminative learning, <em>excessive risk</em> $R_{exessive}$ is decomposed into estimation error (which is associated with sampling bias) and the approximation error (which is associated with the size of the functional class $\mathcal{F}$) as :</p>

<p>$R_{excessive}  = L(f, P)- L(f^* ,P) = (L(f, P) - \mathop{\inf}_{f_n \in \mathcal{F}} L(f_n, P)) \longrightarrow \; {\rm estimation \; error}$</p>

<p>$+ \; ( \mathop{\inf}_{f_n \in \mathcal{f}} L(f_n, p) - L(f^* , p))
\longrightarrow \; {\rm approximation \; error}$</p>

<p>where $f^{\ast}$  denotes the Baysian optimal rule. The term <em>consistency</em> for a sequence of learning algorithms $f_n $ and a distribution $\mathcal{P}$ is defined as:
\begin{eqnarray}
&amp;&amp; L(f_n ; P) - L(f^* ; P) \mathop{\rightarrow}^{L_1}0 \; as \; n \rightarrow \infty
\end{eqnarray}</p>

<p>And with loss bounded from above, by dominate convergence theorem the
consistency criteria is equivalent to convergence in probability:
\begin{eqnarray}
\forall \, \epsilon &gt; 0, \; \mathop{\lim}_{n \leftarrow \infty} P^{\otimes n}[|L(f_n; P)- L(f^*; P)| &lt; \epsilon ] = 1 
\end{eqnarray}</p>

<p>Impossibility result holds for general learning paradigms as well as
discriminative paradigm. No free lunch theorem states the existence of bad
distribution such that small excessive risk can’t be achieved with finite
samples. Therefore discriminative approach confine the functional group to circumvent bad convergent behaviour. This derives the concept of PAC learnibility: There’re some functional class being learnbable, and some that are not.</p>

<p>Note that the lower bound for the imposibility results is established via a key observation: If a
distribution $\mathcal{P}$ is concentrated on a finite set of data $X$ with $P(Y|X)$ being deterministic , then the algorithm output can be highly biased. It’s due to the fact that the training data may not cover all of the element in $X$, which make the algorithm only conduct random guess for the unseen data. (i.e. $f(X_1,Y_1, X_2, Y_2 \dots X_n, Y_n) \perp Y_{\rm test} $)</p>

<h3 id="pac-learnable-realizability">PAC learnable, realizability</h3>

<p>In the discriminative paradigm we aim to minimize the estimation error $\Xi_{\mathcal{F}}(L,P) = L(f,P) -
\mathop{\inf}_{f_n \in \mathcal{F}}L(f_n, P)$, and we’re interested in the
number of samples required to achieve certain ($\epsilon, \delta $)
generalization guarantee. Define the sample complexity of a hypothesis class
$\mathcal{F}$ as</p>

<p>\begin{eqnarray}
&amp;&amp; n_{\mathcal{F}}(\epsilon, \delta) \mathop{=}^{\Delta} {\rm min}[n: \, \exists f_n \in \mathcal{F} \, {\rm s.t.} \, \forall P, \, P^{\otimes n}[\Xi_{\mathcal{F}}(f_n, P) \leq \epsilon] \geq 1-\delta]
\end{eqnarray}</p>

<p>So if there’s some learning algorithm $f_n \in \mathcal{F}$ that guarantee estimation error to be less than
$\epsilon$ with high confident level and finite sample for all distribution,
than such a functional class in PAC learnable.</p>

<p>ERM rule provide a sufficient condition of PAC learnability, via 
\begin{eqnarray}
&amp;&amp; \Xi_{\mathcal{F}}(f_{ERM},P) \leq 2 \mathop{\sup}_{f\in \mathcal{F}}|\Delta
(f,P)|
\end{eqnarray}</p>

<p>Where $\Delta (f, P)$ is the deviation between true risk and the empirical risk.</p>

<p><em>Realizability</em> indicates a existance of $f \in \mathcal{F}$ such that L(f,P) is
zero, which is equivalent to $\ell (f(X), Y) = 0$ with probability one. In this
case:</p>

<ul>
  <li>
    <p>ERM always achieve zero emprirical risk.</p>
  </li>
  <li>
    <p>$f^{*}$ is a deterministic fuction</p>
  </li>
</ul>

<p>Thus any <em>bad</em> function $f_{\rm bad} \in \mathcal{F}$ is less probable to be
picked out from ERM rule. This indeed provided a sample commplexity with smaller
scaling factor $\mathcal{O}(\epsilon^{-1})$, as compared with the agnostic case
$\mathcal{O}(\epsilon^{-2})$</p>

</div>
  <footer>
    <p class="meta">
      <span class="byline author vcard">Posted by <span class="fn">Ping Sheng Kao</span></span>
      <time datetime="2018-06-19T16:47:04+08:00" pubdate data-updated="true"></time>
      <span class="categories">
  
    <a class='category' href='/blog/categories/machinelearning/'>machinelearning</a>
  
</span>
    </p>
    
      <div class="sharing">
  
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://slicerkao.github.io/blog/2018/06/19/study-note-2/" data-via="" data-counturl="http://slicerkao.github.io/blog/2018/06/19/study-note-2/" >Tweet</a>
  
  
  
</div>
    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2018/06/19/study-note/" title="Previous Post: Study Note: Max of subgaussian">&laquo; Study Note: Max of subgaussian</a>
      
      
        <a class="basic-alignment right" href="/blog/2018/06/21/study2/" title="Next Post: Briefing : Derivation of the uniform convergence">Briefing : Derivation of the uniform convergence &raquo;</a>
      
    </p>
  </footer>
</article>


</div>

      </div><!-- /div#content -->
    </div><!-- /div#main -->
  </div><!-- /div.container -->
  <footer><div id="footer-widgets-wrapper">
  <div id="footer-first" class="footer-widget">
    <h3>About Me</h3>
    <section class="about-me">
      
      <div>
        <ul>
          
            <li>GitHub: <a href="https://github.com/SlicerKao">@SlicerKao</a></li>
          
          
            <li>Blog: <a href="http://slicerkao.github.io">http://slicerkao.github.io</a></li>
        </ul>
        <p>
            Machine to learn a quantum leap ?
        </p>
      </div>
    </section>
  </div><!-- /div#footer-second -->


  <div id="footer-second" class="footer-widget">
    <h3>Recent Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="http://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "http://slicerkao.github.io";
        Hatena.BookmarkWidget.title = "Recent Posts";
        Hatena.BookmarkWidget.sort  = "hot";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-second -->

  <div id="footer-third" class="footer-widget">
    <h3>Popular Posts</h3>
    <section id="hatena-popular" class="hatena-bookmark">
      <script language="javascript" type="text/javascript" src="http://b.hatena.ne.jp/js/widget.js" charset="utf-8"></script>
      <script language="javascript" type="text/javascript">
        Hatena.BookmarkWidget.url   = "http://slicerkao.github.io";
        Hatena.BookmarkWidget.title = "Popular Posts";
        Hatena.BookmarkWidget.sort  = "count";
        Hatena.BookmarkWidget.width = 0;
        Hatena.BookmarkWidget.num   = 10;
        Hatena.BookmarkWidget.theme = "notheme";
        Hatena.BookmarkWidget.load();
      </script>
    </section>
  </div><!-- /div#footer-third -->
</div><!-- /div#footer-widgets-wrapper -->

<div id="credit" role="contentinfo">
  <p>
    Copyright &copy; 2020 - <a href="https://github.com/Ping Sheng Kao/">Ping Sheng Kao</a> -
    <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> | Themed with <a href="https://github.com/haya14busa/mjolvim-octotheme">Mjolvim</a></span>
  </p>
</div></footer>
  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>
</body>
</html>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']]
    }
  });
</script>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
